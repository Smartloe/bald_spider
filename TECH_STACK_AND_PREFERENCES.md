# Bald Spider æŠ€æœ¯æ ˆä¸åå¥½

## ğŸ› ï¸ æ ¸å¿ƒæŠ€æœ¯æ ˆ

### Python ç”Ÿæ€ç³»ç»Ÿ
- **Python 3.11+** - åˆ©ç”¨æœ€æ–°çš„è¯­è¨€ç‰¹æ€§
- **asyncio** - å¼‚æ­¥ç¼–ç¨‹åŸºç¡€
- **typing** - ç±»å‹æ³¨è§£æ”¯æŒ
- **uv** - ç°ä»£åŒ…ç®¡ç†å™¨

### å¼‚æ­¥ç¼–ç¨‹
```python
# æ¨èï¼šä½¿ç”¨ async/await
async def fetch_data(url: str) -> str:
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¼‚æ­¥æ“ä½œ
    return "data"

# é¿å…ï¼šåŒæ­¥é˜»å¡è°ƒç”¨
def fetch_data_sync(url: str) -> str:
    time.sleep(0.1)  # é˜»å¡æ“ä½œ
    return "data"
```

### åŒ…ç®¡ç†
```toml
# pyproject.toml
[project]
name = "bald-spider"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "requests>=2.32.5",
]

[project.optional-dependencies]
dev = [
    "black>=25.9.0",
    "pytest>=8.4.2",
]
```

## ğŸ¯ è®¾è®¡åŸåˆ™

### 1. å¼‚æ­¥ä¼˜å…ˆ
- æ‰€æœ‰ I/O æ“ä½œå¿…é¡»å¼‚æ­¥
- é¿å…é˜»å¡ä¸»çº¿ç¨‹
- ä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å¼å¤„ç†æ•°æ®æµ

### 2. ç±»å‹å®‰å…¨
- å¼ºåˆ¶ç±»å‹æ³¨è§£
- ä½¿ç”¨ç±»å‹æ£€æŸ¥å·¥å…·
- è¿è¡Œæ—¶ç±»å‹éªŒè¯

### 3. é”™è¯¯å¤„ç†
- ä¼˜é›…çš„å¼‚å¸¸å¤„ç†
- ä»»åŠ¡çº§åˆ«çš„é”™è¯¯éš”ç¦»
- å¯é…ç½®çš„é‡è¯•æœºåˆ¶

### 4. å¯æ‰©å±•æ€§
- æ¨¡å—åŒ–è®¾è®¡
- æ’ä»¶ç³»ç»Ÿæ”¯æŒ
- æ¥å£æŠ½è±¡æ¸…æ™°

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### å¹¶å‘æ§åˆ¶
```python
# ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
semaphore = asyncio.Semaphore(16)

async def limited_task():
    async with semaphore:
        # æ‰§è¡Œä»»åŠ¡
        pass
```

### å†…å­˜ç®¡ç†
```python
# ä½¿ç”¨ç”Ÿæˆå™¨é¿å…å¤§é‡æ•°æ®åŠ è½½
def generate_requests(urls):
    for url in urls:
        yield Request(url)

# åŠæ—¶æ¸…ç†èµ„æº
async def cleanup():
    if hasattr(self, '_resource'):
        await self._resource.close()
        del self._resource
```

### ç½‘ç»œä¼˜åŒ–
```python
# è¿æ¥æ± å¤ç”¨ï¼ˆå¾…å®ç°ï¼‰
async def create_client():
    return httpx.AsyncClient(
        limits=httpx.Limits(
            max_connections=100,
            max_keepalive_connections=20
        )
    )
```

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•
```python
@pytest.mark.asyncio
async def test_request_creation():
    request = Request(url="https://example.com")
    assert request.url == "https://example.com"
```

### é›†æˆæµ‹è¯•
```python
@pytest.mark.asyncio
async def test_spider_integration():
    spider = TestSpider()
    engine = Engine()
    await engine.start_spider(spider)
    # éªŒè¯ç»“æœ
```

### æ€§èƒ½æµ‹è¯•
```python
async def benchmark_crawl():
    start_time = time.time()
    # è¿è¡Œçˆ¬è™«
    await run_spider()
    duration = time.time() - start_time
    assert duration < 60  # åº”åœ¨60ç§’å†…å®Œæˆ
```

## ğŸ”§ å¼€å‘å·¥å…·

### ä»£ç æ ¼å¼åŒ–
```bash
# ä½¿ç”¨ black æ ¼å¼åŒ–ä»£ç 
uv run black .

# æ£€æŸ¥æ ¼å¼
uv run black --check .
```

### ç±»å‹æ£€æŸ¥
```bash
# ä½¿ç”¨ mypy æ£€æŸ¥ç±»å‹
mypy bald_spider/
```

### æµ‹è¯•è¿è¡Œ
```bash
# è¿è¡Œæµ‹è¯•
uv run pytest

# å¸¦è¦†ç›–ç‡çš„æµ‹è¯•
uv run pytest --cov=bald_spider
```

## ğŸ“‹ ä»£ç è§„èŒƒ

### å‘½åçº¦å®š
```python
# ç±»åä½¿ç”¨ PascalCase
class SpiderEngine:
    pass

# å‡½æ•°å’Œå˜é‡ä½¿ç”¨ snake_case
def start_spider():
    pass

# å¸¸é‡ä½¿ç”¨ UPPER_SNAKE_CASE
MAX_CONCURRENCY = 16
```

### å¯¼å…¥é¡ºåº
```python
# æ ‡å‡†åº“
import asyncio
import time
from typing import Optional, Generator

# ç¬¬ä¸‰æ–¹åº“
import requests

# æœ¬åœ°æ¨¡å—
from bald_spider.http.request import Request
from bald_spider.spider import Spider
```

### æ–‡æ¡£å­—ç¬¦ä¸²
```python
async def fetch_data(url: str) -> str:
    """
    å¼‚æ­¥è·å–ç½‘é¡µæ•°æ®
    
    Args:
        url: ç›®æ ‡ç½‘é¡µURL
        
    Returns:
        ç½‘é¡µå†…å®¹å­—ç¬¦ä¸²
        
    Raises:
        RequestError: å½“è¯·æ±‚å¤±è´¥æ—¶
        TimeoutError: å½“è¯·æ±‚è¶…æ—¶æ—¶
    """
    pass
```

## ğŸš€ æ€§èƒ½ç›‘æ§

### æŒ‡æ ‡æ”¶é›†
```python
class Metrics:
    def __init__(self):
        self.requests_count = 0
        self.errors_count = 0
        self.start_time = time.time()
    
    def increment_requests(self):
        self.requests_count += 1
    
    def increment_errors(self):
        self.errors_count += 1
    
    @property
    def requests_per_second(self):
        elapsed = time.time() - self.start_time
        return self.requests_count / elapsed if elapsed > 0 else 0
```

### æ—¥å¿—é…ç½®
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('spider.log'),
        logging.StreamHandler()
    ]
)
```

## ğŸ”’ å®‰å…¨è€ƒè™‘

### è¯·æ±‚å®‰å…¨
```python
# éªŒè¯URLæ ¼å¼
def validate_url(url: str) -> bool:
    try:
        result = urllib.parse.urlparse(url)
        return all([result.scheme, result.netloc])
    except Exception:
        return False

# é™åˆ¶è¯·æ±‚é¢‘ç‡
class RateLimiter:
    def __init__(self, max_requests: int, window: int):
        self.max_requests = max_requests
        self.window = window
        self.requests = []
    
    async def acquire(self):
        now = time.time()
        # æ¸…ç†è¿‡æœŸè®°å½•
        self.requests = [r for r in self.requests if now - r < self.window]
        
        if len(self.requests) >= self.max_requests:
            await asyncio.sleep(self.window)
        
        self.requests.append(now)
```

### æ•°æ®éªŒè¯
```python
from dataclasses import dataclass
from typing import Optional

@dataclass
class SafeItem:
    title: str
    url: str
    content: Optional[str] = None
    
    def __post_init__(self):
        if not self.title or len(self.title) > 1000:
            raise ValueError("Title is required and must be under 1000 characters")
        
        if not validate_url(self.url):
            raise ValueError("Invalid URL format")
```

## ğŸ“ˆ æœªæ¥è§„åˆ’

### çŸ­æœŸç›®æ ‡
- [ ] é›†æˆçœŸå® HTTP å®¢æˆ·ç«¯ï¼ˆhttpx/aiohttpï¼‰
- [ ] å®ç°è¯·æ±‚å»é‡æœºåˆ¶
- [ ] æ·»åŠ ä¸­é—´ä»¶ç³»ç»Ÿ
- [ ] å®Œå–„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

### ä¸­æœŸç›®æ ‡
- [ ] å®ç°æ•°æ®ç®¡é“ç³»ç»Ÿ
- [ ] æ·»åŠ åˆ†å¸ƒå¼æ”¯æŒ
- [ ] å®ç°æŒä¹…åŒ–å­˜å‚¨
- [ ] å®Œå–„ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ

### é•¿æœŸç›®æ ‡
- [ ] æ”¯æŒ JavaScript æ¸²æŸ“é¡µé¢
- [ ] å®ç°æ™ºèƒ½åçˆ¬è™«ç­–ç•¥
- [ ] æä¾› Web ç®¡ç†ç•Œé¢
- [ ] æ„å»ºæ’ä»¶ç”Ÿæ€ç³»ç»Ÿ